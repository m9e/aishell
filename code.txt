// user_interface.py
import os

class UserInterface:
    def __init__(self):
        self.interactive_mode = False

    def get_instruction(self):
        return input("Enter instruction: ")

    def get_question(self):
        return input("Enter question: ")

    def get_limit(self):
        return int(input("Enter new execution limit: "))

    def display_command(self, command):
        print(f"Generated command: {command}")

    def display_answer(self, answer):
        print(f"Answer: {answer}")

    def display_message(self, message):
        print(message)

    def toggle_interactive_mode(self):
        self.interactive_mode = not self.interactive_mode
        print(f"Interactive mode {'enabled' if self.interactive_mode else 'disabled'}.")

    def confirm_execution(self):
        return input("Execute command? (y/n): ").lower() == 'y'

    def display_prompt(self):
        print(f"{os.getcwd()}$ ", end='', flush=True)

// aishell.py
import os
import sys
import subprocess
from prompt_toolkit import PromptSession
from prompt_toolkit.history import FileHistory
from prompt_toolkit.auto_suggest import AutoSuggestFromHistory
from prompt_toolkit.lexers import PygmentsLexer
from pygments.lexers.shell import BashLexer

from llm_interface import LLMInterface
from command_executor import CommandExecutor
from context_manager import ContextManager

class AIShell:
    def __init__(self):
        self.llm_interface = LLMInterface()
        self.command_executor = CommandExecutor()
        self.context_manager = ContextManager()
        self.running = True
        self.session = PromptSession(
            history=FileHistory(os.path.expanduser('~/.aishell_history')),
            auto_suggest=AutoSuggestFromHistory(),
            lexer=PygmentsLexer(BashLexer)
        )

    def run(self):
        while self.running:
            try:
                command = self.session.prompt(f"{os.getcwd()}$ ")
                self.execute_command(command)
            except KeyboardInterrupt:
                continue
            except EOFError:
                print("Exiting AIShell...")
                self.running = False

    def execute_command(self, command):
        if command.strip() == "exit":
            print("Exiting AIShell...")
            self.running = False
            return

        if command.strip().startswith("llm"):
            instruction = command.strip()[4:]
            llm_response = self.llm_interface.generate_command(instruction)
            print(f"Generated command: {llm_response}")
            if input("Execute command? (y/n): ").lower() == 'y':
                self.run_shell_command(llm_response)
        else:
            self.run_shell_command(command)

    def run_shell_command(self, command):
        try:
            process = subprocess.Popen(
                command,
                shell=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    print(output.strip())
            
            for line in process.stderr:
                print(line.strip(), file=sys.stderr)

            return_code = process.poll()
            if return_code:
                print(f"Command exited with return code {return_code}", file=sys.stderr)
        except Exception as e:
            print(f"Error executing command: {e}", file=sys.stderr)

def main():
    aishell = AIShell()
    aishell.run()

if __name__ == "__main__":
    main()

// context_manager.py
from collections import deque

class ContextManager:
    def __init__(self, max_lines=500):
        self.context = deque(maxlen=max_lines)

    def add_line(self, line):
        self.context.append(line)

    def get_context(self):
        return "\n".join(self.context)

// terminal_controller.py
import os
import sys
import termios
import tty

class TerminalController:
    def __init__(self):
        self.old_settings = termios.tcgetattr(sys.stdin)

    def __enter__(self):
        tty.setraw(sys.stdin.fileno())
        return self

    def __exit__(self, type, value, traceback):
        termios.tcsetattr(sys.stdin, termios.TCSADRAIN, self.old_settings)

    def getch(self):
        return os.read(sys.stdin.fileno(), 1)

    def handle_ctrl_i(self):
        sys.stdout.write("\nInstruction? (n/s/a/l/i): ")
        sys.stdout.flush()
        return self.getch().decode('utf-8')

// test_aishell.py
import sys
import pytest
from unittest.mock import Mock, patch
import os
from collections import deque

# Imports (keep them as they are in your current file)
from context_manager import ContextManager
from llm_interface import LLMInterface
from command_executor import CommandExecutor
from user_interface import UserInterface

# Fixtures
@pytest.fixture
def context_manager():
    return ContextManager(max_lines=5)

@pytest.fixture
def mock_azure_client():
    with patch('llm_interface.AzureOpenAI') as mock_azure:
        mock_client = Mock()
        mock_azure.return_value = mock_client
        yield mock_client

@pytest.fixture
def llm_interface(mock_azure_client):
    return LLMInterface()

@pytest.fixture
def command_executor():
    return CommandExecutor()

@pytest.fixture
def user_interface():
    return UserInterface()

# Tests for ContextManager
def test_context_manager_add_and_get(context_manager):
    context_manager.add_line("Line 1")
    context_manager.add_line("Line 2")
    assert context_manager.get_context() == "Line 1\nLine 2"

def test_context_manager_max_lines(context_manager):
    for i in range(10):
        context_manager.add_line(f"Line {i}")
    assert len(context_manager.context) == 5
    assert context_manager.get_context().startswith("Line 5")

# Tests for LLMInterface
def test_llm_interface_generate_command(llm_interface, mock_azure_client):
    # Create a mock response that mimics the structure of the actual API response
    mock_response = Mock()
    mock_response.choices = [Mock(message=Mock(content="echo 'Hello, World!'"))]
    mock_azure_client.chat.completions.create.return_value = mock_response
    
    command = llm_interface.generate_command("Print Hello World")
    assert command == "echo 'Hello, World!'"

def test_llm_interface_answer_question(llm_interface, mock_azure_client):
    # Create a mock response that mimics the structure of the actual API response
    mock_response = Mock()
    mock_response.choices = [Mock(message=Mock(content="Sunny"))]
    mock_azure_client.chat.completions.create.return_value = mock_response
    
    answer = llm_interface.answer_question("What's the weather?", "Context: It's a clear day.")
    assert answer == "Sunny"

def test_llm_interface_error_handling(llm_interface, mock_azure_client):
    mock_azure_client.chat.completions.create.side_effect = Exception("API Error")
    command = llm_interface.generate_command("This will fail")
    assert command is None

# Tests for CommandExecutor
@patch('subprocess.run')
def test_command_executor_execute(mock_run, command_executor):
    mock_run.return_value.stdout = "Command output"
    command_executor.execute("echo 'test'")
    mock_run.assert_called_once_with("echo 'test'", shell=True, check=True, text=True, capture_output=True)

def test_command_executor_limit(command_executor):
    command_executor.set_limit(2)
    for _ in range(3):
        with patch('subprocess.run') as mock_run:
            command_executor.execute("test")
    assert command_executor.execution_count == 2

# Tests for UserInterface
@patch('builtins.input')
@patch('builtins.print')
def test_user_interface_get_instruction(mock_print, mock_input, user_interface):
    mock_input.return_value = "list files"
    instruction = user_interface.get_instruction()
    assert instruction == "list files"

@patch('builtins.print')
def test_user_interface_display_command(mock_print, user_interface):
    user_interface.display_command("ls -la")
    mock_print.assert_called_once_with("Generated command: ls -la")

def test_user_interface_toggle_interactive_mode(user_interface):
    assert not user_interface.interactive_mode
    user_interface.toggle_interactive_mode()
    assert user_interface.interactive_mode
    user_interface.toggle_interactive_mode()
    assert not user_interface.interactive_mode

# Integration test
def test_integration_generate_and_execute():
    llm_interface = LLMInterface()
    command_executor = CommandExecutor()
    user_interface = UserInterface()

    with patch.object(llm_interface, 'generate_command', return_value="echo 'Integration Test'"):
        with patch.object(command_executor, 'execute') as mock_execute:
            instruction = "Run an integration test"
            llm_response = llm_interface.generate_command(instruction)
            user_interface.display_command(llm_response)
            command_executor.execute(llm_response)

            mock_execute.assert_called_once_with("echo 'Integration Test'")

# Environmental variable test
def test_environment_variables():
    required_vars = ['AZURE_OPENAI_API_KEY', 'AZURE_OPENAI_ENDPOINT', 'AZURE_OPENAI_DEPLOYMENT_NAME']
    for var in required_vars:
        assert os.getenv(var) is not None, f"Environment variable {var} is not set"

@pytest.mark.integration
def test_real_api_call():
    llm_interface = LLMInterface()
    
    # Test generate_command
    try:
        command = llm_interface.generate_command("List all files in the current directory")
        assert command is not None
        assert isinstance(command, str)
        print(f"\nGenerated command: {command}", file=sys.stderr)
        
    except Exception as e:
        pytest.fail(f"generate_command failed with error: {str(e)}")
    
    # Test answer_question
    try:
        answer = llm_interface.answer_question("What's the capital of France?", "")
        assert answer is not None
        assert isinstance(answer, str)
        print(f"\nAnswer to 'What's the capital of France?': {answer}", file=sys.stderr)
        
    except Exception as e:
        pytest.fail(f"answer_question failed with error: {str(e)}")




if __name__ == "__main__":
    pytest.main([__file__])

// command_executor.py
import subprocess
import threading
import signal
import json
import sys

class CommandExecutor:
    def __init__(self):
        self.limit = None
        self.execution_count = 0
        self.current_process = None

    def execute(self, command_json):
        if self.limit and self.execution_count >= self.limit:
            print("Execution limit reached. Use 'Ctrl-I l' to set a new limit.")
            return

        try:
            command_dict = json.loads(command_json)
            if "bash" not in command_dict:
                print("Invalid command format. Expected JSON with 'bash' key.")
                return

            command = command_dict["bash"]
            self.current_process = subprocess.Popen(command, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            
            def read_output(pipe, file):
                for line in iter(pipe.readline, ''):
                    file.write(line)
                    file.flush()

            stdout_thread = threading.Thread(target=read_output, args=(self.current_process.stdout, sys.stdout))
            stderr_thread = threading.Thread(target=read_output, args=(self.current_process.stderr, sys.stderr))

            stdout_thread.start()
            stderr_thread.start()

            self.current_process.wait()
            stdout_thread.join()
            stderr_thread.join()

            self.execution_count += 1
        except json.JSONDecodeError as e:
            print(f"Error decoding JSON command: {e}", file=sys.stderr)
        except subprocess.CalledProcessError as e:
            print(f"Error executing command: {e}", file=sys.stderr)
        finally:
            self.current_process = None

    def stop_current_command(self):
        if self.current_process:
            self.current_process.send_signal(signal.SIGINT)

    def set_limit(self, limit):
        self.limit = limit
        self.execution_count = 0

// __init__.py


// llm_interface.py
import os
import json
import sys
from openai import AzureOpenAI

class LLMInterface:
    def __init__(self):
        self.client = AzureOpenAI(
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),  
            api_version="2023-12-01-preview",
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
        )
        self.deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")

    def is_valid_bash_command(self, response_content: str) -> bool:
        try:
            response_json = json.loads(response_content)
            return isinstance(response_json, dict) and "bash" in response_json and isinstance(response_json["bash"], str)
        except json.JSONDecodeError:
            return False

    def generate_command(self, instruction):
        messages = [
            {"role": "system", "content": "You are an AI assistant that generates bash commands. You are in a terminal, and so you adhere very strictly to formatting requests."},
            {"role": "user", "content": f'Generate a bash command for: {instruction}; output it in the format: {{"bash": "<command>"}}'}
        ]

        retries = 2

        while retries > 0:
            try:
                response = self.client.chat.completions.create(
                    model=self.deployment_name,
                    messages=messages
                )
                response_content = response.choices[0].message.content.strip()

                # Extract JSON part from the response content
                start_index = response_content.find('{')
                end_index = response_content.rfind('}') + 1
                if start_index != -1 and end_index != -1:
                    response_content = response_content[start_index:end_index]

                if self.is_valid_bash_command(response_content):
                    return response_content["bash"]
                else:
                    messages.append({"role": "assistant", "content": response_content})
                    messages.append({"role": "user", "content": 'Your format is invalid and MUST be in the form of {"bash": "<command>"} as valid JSON.'})
                    retries -= 1
            except Exception as e:
                print(f"Error generating command: {e}", file=sys.stderr)
                return False

        print("The LLM could not properly respond after multiple attempts.", file=sys.stderr)
        return False

    def answer_question(self, question, context):
        try:
            response = self.client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "You are an AI assistant that answers questions based on given context."},
                    {"role": "user", "content": f"Context: {context}\n\nQuestion: {question}"}
                ]
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error answering question: {e}")
            return None

